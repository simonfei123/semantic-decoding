{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sphere/projects/simon/semantic-decoding/pyenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "import config\n",
    "from utils_eval import generate_null, load_transcript, windows, segment_data, WER, BLEU, METEOR, BERTSCORE\n",
    "from utils_ridge.textgrid import TextGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(config.DATA_TEST_DIR, \"eval_segments.json\"), \"r\") as f:\n",
    "        eval_segments = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = np.load('../results/S1/perceived_speech/wheretheressmoke_2.npz')\n",
    "pred_words, pred_times = pred_data[\"words\"], pred_data[\"times\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1589)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_checkpoint = \"perceived\"\n",
    "null_word_list = generate_null(pred_times, gpt_checkpoint, 10)\n",
    "np.array(null_word_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_scores, window_zscores = {}, {}\n",
    "story_scores, story_zscores = {}, {}\n",
    "reference = 'wheretheressmoke'\n",
    "grid_path = '../data_test/test_stimulus/perceived_speech/wheretheressmoke.TextGrid'\n",
    "experiment = \"perceived_speech\"\n",
    "skip_words = frozenset([\"sentence_start\", \"sentence_end\", \"br\", \"lg\", \"ls\", \"ns\", \"sp\"])\n",
    "transcript_data = {}\n",
    "with open(grid_path) as f: \n",
    "    grid = TextGrid(f.read())\n",
    "    if experiment == \"perceived_speech\": transcript = grid.tiers[1].make_simple_transcript()\n",
    "    else: transcript = grid.tiers[0].make_simple_transcript()\n",
    "    transcript = [(float(s), float(e), w.lower()) for s, e, w in transcript if w.lower().strip(\"{}\").strip() not in skip_words]\n",
    "transcript_data[\"words\"] = np.array([x[2] for x in transcript])\n",
    "transcript_data[\"times\"] = np.array([(x[0] + x[1]) / 2 for x in transcript])\n",
    "ref_data = transcript_data\n",
    "ref_words, ref_times = ref_data[\"words\"], ref_data[\"times\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment prediction and reference words into windows\n",
    "window_cutoffs = windows(*eval_segments[reference], config.WINDOW)\n",
    "ref_windows = segment_data(ref_words, ref_times, window_cutoffs)\n",
    "pred_windows = segment_data(pred_words, pred_times, window_cutoffs)\n",
    "# pred_windows = segment_data(pred_words, ref_times, window_cutoffs)\n",
    "null_window_list = [segment_data(null_words, pred_times, window_cutoffs) for null_words in null_word_list]\n",
    "# null_window_list = [segment_data(null_words, ref_times, window_cutoffs) for null_words in null_word_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sphere/projects/simon/semantic-decoding/pyenv/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for bleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/bleu/bleu.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/mnt/sphere/projects/simon/semantic-decoding/pyenv/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for meteor contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/meteor/meteor.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package wordnet to /home/AD/tfei/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/AD/tfei/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/AD/tfei/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'utils_eval.BLEU'> [0.18409899 0.19254194 0.19817932 0.18524355 0.19031435 0.18813607\n",
      " 0.17506497 0.18536413 0.19678263 0.19183578]\n",
      "<class 'utils_eval.METEOR'> [0.13769624 0.14041239 0.14710585 0.13563184 0.1393142  0.13539227\n",
      " 0.13102061 0.13276535 0.13968289 0.1417376 ]\n",
      "<class 'utils_eval.BERTSCORE'> [0.78914654 0.7897891  0.7902786  0.78892934 0.7891053  0.7910224\n",
      " 0.78970736 0.7902623  0.78855485 0.7883179 ]\n"
     ]
    }
   ],
   "source": [
    "for metric in [BLEU(n = 1), METEOR(), BERTSCORE(\n",
    "        idf_sents = np.load(os.path.join(config.DATA_TEST_DIR, \"idf_segments.npy\")), rescale = False, \n",
    "        score = \"recall\")]:\n",
    "    # get null score for each window and the entire story\n",
    "    window_null_scores = np.array([metric.score(ref = ref_windows, pred = null_windows) \n",
    "                                    for null_windows in null_window_list])\n",
    "    # window_null_scores = np.array([BLEU(n = 1).score(ref = ref_windows[:475], pred = null_windows[:475]) \n",
    "    #                                 for null_windows in null_window_list])\n",
    "    story_null_scores = window_null_scores.mean(1)\n",
    "    print(type(metric), story_null_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sphere/projects/simon/semantic-decoding/pyenv/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for bleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/bleu/bleu.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/mnt/sphere/projects/simon/semantic-decoding/pyenv/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for meteor contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/meteor/meteor.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package wordnet to /home/AD/tfei/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/AD/tfei/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/AD/tfei/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'utils_eval.BLEU'> 0.23056336621182172\n",
      "<class 'utils_eval.METEOR'> 0.17134205187930937\n",
      "<class 'utils_eval.BERTSCORE'> 0.8056429\n"
     ]
    }
   ],
   "source": [
    "# get raw score and normalized score for each window\n",
    "for metric in [BLEU(n = 1), METEOR(), BERTSCORE(\n",
    "        idf_sents = np.load(os.path.join(config.DATA_TEST_DIR, \"idf_segments.npy\")), rescale = False, \n",
    "        score = \"recall\")]:\n",
    "    window_scores = metric.score(ref = ref_windows, pred = pred_windows)\n",
    "    print(type(metric), window_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(480):\n",
    "#     print(len(ref_windows[i]), len(pred_windows[i]), len(null_window_list[0][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
